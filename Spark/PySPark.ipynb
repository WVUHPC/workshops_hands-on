{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "first-tomorrow",
   "metadata": {},
   "source": [
    "# Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-ensemble",
   "metadata": {},
   "source": [
    "**Apache Spark** is an open-source unified analytics engine for large-scale data processing. \n",
    "\n",
    "Spark provides an interface for programming entire clusters with implicit data parallelism and fault tolerance. \n",
    "\n",
    "Originally developed at the University of California, Berkeley's AMPLab, the Spark codebase was later donated to the Apache Software Foundation, which has maintained it since."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "equal-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "clean-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-volunteer",
   "metadata": {},
   "source": [
    "# Spark Features beyond Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-coating",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    " * Use RAM as much as possible\n",
    " * Be smarter in distributing load\n",
    " * Ease of Use\n",
    " * Use languages such as **Python**, **Scala** and **Java**\n",
    "\n",
    "## New Paradigms\n",
    "\n",
    " * SparkSQL\n",
    " * Streaming\n",
    " * MLib\n",
    " * GraphX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-belgium",
   "metadata": {},
   "source": [
    "## Open a Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aerial-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"Test_App\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-passion",
   "metadata": {},
   "source": [
    "## Download all Shakespeare Works from Gutenberg Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-guyana",
   "metadata": {},
   "source": [
    "https://www.gutenberg.org/files/100/100-0.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-prison",
   "metadata": {},
   "source": [
    "## Create a DataSet from the text file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-quarter",
   "metadata": {},
   "source": [
    "A Resilient Distributed Dataset (RDD), the basic abstraction in Spark. \n",
    "\n",
    "RDD represents an **immutable**, **partitioned** collection of elements that can be operated on in parallel.\n",
    "\n",
    "http://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.html#pyspark.RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "latest-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_rdd = sc.textFile(\"100-0.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-seattle",
   "metadata": {},
   "source": [
    "# Transformations vs Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-rabbit",
   "metadata": {},
   "source": [
    "**Transformations** are where the Spark machinery can do its magic with lazy evaluation and clever algorithms to minimize communication and parallelize the processing. You want to keep your data in the RDDs as much as possible.\n",
    "\n",
    "**Actions** are mostly used either at the end of the analysis when the data has been distilled down (collect), or along the way to \"peek\" at the process (count, take)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-magazine",
   "metadata": {},
   "source": [
    "## Common Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-boards",
   "metadata": {},
   "source": [
    "|Action | Result |\n",
    "| :- | :- |\n",
    "| collect() | Return all the elements from the RDD.\n",
    "| count() | Number of elements in RDD.\n",
    "| countByValue() | List of times each value occurs in the RDD.\n",
    "| reduce(func) | Aggregate the elements of the RDD by providing a function which combines any two into one (sum, min, max, ...).\n",
    "| first(), take(n) | Return the first, or first n elements.\n",
    "| top(n) | Return the n highest valued elements of the RDDs.\n",
    "| takeSample(...) | Various options to return a subset of the RDD..\n",
    "| saveAsTextFile(path) | Write the elements as a text file.\n",
    "| foreach(func) | Run the func on each element. Used for side-effects (updating accumulator variables) or interacting with external systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-soldier",
   "metadata": {},
   "source": [
    "## A few *actions* exploring the data from the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "architectural-mouse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170592"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ordinary-spine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "961441"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_rdd = lines_rdd.flatMap(lambda x: x.split())\n",
    "words_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-dress",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "identical-ladder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 1), ('Project', 1), ('Gutenberg', 1), ('eBook', 1), ('of', 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_value_rdd = words_rdd.map(lambda x: (x,1))\n",
    "key_value_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "functional-square",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 4435),\n",
       " ('Project', 79),\n",
       " ('Gutenberg', 22),\n",
       " ('eBook', 6),\n",
       " ('of', 16819)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_rdd = key_value_rdd.reduceByKey(lambda x,y: x+y)\n",
    "word_counts_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "amino-frederick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4435, 'The'),\n",
       " (79, 'Project'),\n",
       " (22, 'Gutenberg'),\n",
       " (6, 'eBook'),\n",
       " (16819, 'of')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flipped_rdd = word_counts_rdd.map(lambda x: (x[1],x[0]))\n",
    "flipped_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "differential-virginia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25519, 'the'), (20668, 'I'), (19840, 'and'), (17012, 'to'), (16819, 'of')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_rdd = flipped_rdd.sortByKey(False)\n",
    "results_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-detector",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
